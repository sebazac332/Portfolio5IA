{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Impress\u00f5es gerais","text":"<p>Nesta unidade veremos algoritmos mais direcionados \u00e0 previs\u00e3o de eventos no futuro, geralmente baseados em eventos passados para inferir o que vai acontecer, Voc\u00ea tamb\u00e9m ver\u00e1 princ\u00edpios b\u00e1sicos de estat\u00edstica e quais s\u00e3o as formas em que esses algoritmos tomam decis\u00f5es quando encontram incertezas. Os algoritmos espec\u00edficos que vimos s\u00e3o Redes Bayesianas, Modelo Oculto de Markov e Filtros de Kalman.</p>"},{"location":"basic_notation/","title":"Nota\u00e7\u00e3o b\u00e1sica de probabilidade\u200b","text":"<p>Refere-se aos s\u00edmbolos e conven\u00e7\u00f5es usados para representar e manipular probabilidades e conceitos estat\u00edsticos. Essa nota\u00e7\u00e3o \u00e9 fundamental em campos como estat\u00edstica, aprendizado de m\u00e1quina e intelig\u00eancia artificial, onde lidar com a incerteza e a variabilidade \u00e9 crucial. [5]</p>"},{"location":"basic_notation/#notacoes","title":"Nota\u00e7\u00f5es","text":"<ul> <li>Probabilidade de um evento A ocorrer: P(A)<ul> <li>Conjunto de probabilidades de todos os poss\u00edveis valores de A \u00e9 conhecida como distribui\u00e7\u00e3o de probabilidade.</li> <li>Probabilidade de todos os poss\u00edveis resultados de um evento A:<ul> <li>P(A = a) = 0.25 (25% de probabilidade do resultado de A ser a)</li> <li>P(A = b) = 0.25 (25% de probabilidade do resultado de A ser b)</li> <li>P(A = c) = 0.25 (25% de probabilidade do resultado de A ser b)</li> <li>P(A = d) = 0.25 (25% de probabilidade do resultado de A ser b)</li> </ul> </li> <li>Forma abreviada de todos os poss\u00edveis resultados:<ul> <li>P(A) = &lt;0.25,0.25,0.25,0.25&gt;</li> </ul> </li> <li>Quando se tem um rango finito e discreto, se conhece como distribui\u00e7\u00e3o categ\u00f3rica.</li> <li>O conjunto de todos os valores poss\u00edveis de A quando A \u00e9 uma vari\u00e1vel cont\u00ednua:<ul> <li>P(A = x) = Uniform(x,10,18)</li> </ul> </li> <li>Significa que os valores de A est\u00e3o uniformemente distribu\u00eddos entre 10 e 18.</li> <li>Essa representa\u00e7\u00e3o \u00e9 conhecida como fun\u00e7\u00e3o de densidade de probabilidade.</li> </ul> </li> <li>Probabilidade de um evento A n\u00e3o ocorrer: P(\u00acA)<ul> <li>Rela\u00e7\u00e3o entre a probabilidade de um evento acontecer e a probabilidade de n\u00e3o acontecer:<ul> <li>P(\u00acA) = 1 - P(A)</li> </ul> </li> </ul> </li> <li>Probabilidade de um evento A e um evento B ocorrerem ao mesmo tempo: P(A \u2227 B)<ul> <li>Representa\u00e7\u00e3o de todos os valores poss\u00edveis de A e B: P(A,B) = P(A|B)P(B)</li> <li>Essa representa\u00e7\u00e3o \u00e9 conhecida como distribui\u00e7\u00e3o conjunta de probabilidade e \u00e9 a distribui\u00e7\u00e3o da probabilidade de que os eventos A e B ocorram simultaneamente.</li> <li>Um modelo de probabilidade \u00e9 completamente determinado pela distribui\u00e7\u00e3o conjunta de todas as vari\u00e1veis \u200b\u200baleat\u00f3rias, as chamadas distribui\u00e7\u00e3o de probabilidade conjunta completa. [1]</li> </ul> </li> <li>Probabilidade de um evento A ou evento B ocorrer: P(A \u2228 B)<ul> <li>Para calcular a probabilidade da disjun\u00e7\u00e3o P(A \u2228 B) usa-se o princ\u00edpio de inclus\u00e3o-exclus\u00e3o:<ul> <li>P(A \u2228 B) = P(A) + P(B) \u2212 P(A \u2227 B) .</li> </ul> </li> </ul> </li> <li>Probabilidade de um evento A acontecer e um evento B n\u00e3o acontecer: P(A \u2227 \u00acB)</li> <li>Probabilidade de n\u00e3o ocorrer um evento A ou ocorrer um evento B: P(\u00acA \u2228 B)</li> <li>A probabilidade de ocorr\u00eancia do evento A, considerando que o evento B tenha ocorrido (Probabilidade condicional): P(A|B) -&gt; P(A \u2227 B)/P(B)<ul> <li>Forma alternativa chamada regra de produto: P(A \u2227 B) = P(A|B)P(B)</li> </ul> </li> <li>Teorema de Bayes, que fornece uma maneira de atualizar as probabilidades com base em novos dados: P(A|B) = P(B)P(B\u2223A)*P(A)</li> </ul>"},{"location":"basic_notation/#inferencia-usando-distribuicoes-conjuntas-completas","title":"Infer\u00eancia usando distribui\u00e7\u00f5es conjuntas completas","text":"<p>Dom\u00ednio composto por 3 vari\u00e1veis A, B e C:</p> B B \u00acB \u00acB C \u00acC C \u00acC A 0.108 0.012 0.072 0.008 \u00acA 0.016 0.064 0.144 0.576 <p>Calcular probabilidade de A ou B: Soma as probabilidades onde A \u00e9 verdadeiro e B falso com as probabilidades onde A \u00e9 falso e B verdadeiro. P(A \u2228 B) = 0.18 + 0.016 + 0.012 + 0.064 + 0.072 + 0.008 = 0.28</p> <p>Calcular probabilidade de A: Soma as probabilidades onde A \u00e9 verdadeiro. P(A) = 0.108 + 0.012 + 0.072 + 0.008 = 0.2</p> <p>Esse processo onde todas as probabilidades s\u00e3o somadas \u00e9 conhecido como marginaliza\u00e7\u00e3o. Esta tem a forma geral: [1] $$ P(Y) = \\sum_{z} P(Y, Z = z) $$</p> <p>Onde Y e Z s\u00e3o vari\u00e1veis.</p> <p>Substituindo P(Y,z) por P(Y|z)P(z) voc\u00ea obt\u00e9m outra regra chamada condicionamento. [1] $$ P(Y) = \\sum_{z} P(Y \\mid Z = z) \\, P(Z = z) $$</p> <p>Onde Y e Z s\u00e3o vari\u00e1veis.</p> <p>Para calcular a probabilidade condicional de A dada evid\u00eancia de B:</p> <p>P(A|B) = P(A \u2228 B)/P(B) = (0.108 + 0.012)/(0.108 + 0.012 + 0.016 + 0.064) = 0.6</p> <p>Para calcular a probabilidade condicional de A n\u00e3o acontecer dada evid\u00eancia de B:</p> <p>P(\u00acA|B) = P(\u00acA \u2228 B)/P(B) = (0.016 + 0.064)/(0.108 + 0.012 + 0.016 + 0.064) = 0.4</p> <p>Para obter a normaliza\u00e7\u00e3o de probabilidades:</p> <p>P(A|B) = \u03b1P(A, B) = \u03b1[P(A, B, C)+P(A, B, \u00acC)] = \u03b1[&lt;0.108,0.016&gt; + &lt;0.012,0.064&gt;] = \u03b1&lt;0.12,0.08&gt; = &lt;0.6,0.4&gt;</p> <p>Usando isso voc\u00ea pode obter P(A|B) sem saber o valor de P(B).</p> <p>Processo geral de infer\u00eancia:</p> \\[ P(X \\mid e) = \\alpha \\, P(X, e) = \\alpha \\sum_{y} P(X, e, y) \\] <p>Onde X e vari\u00e1vel, E a lista de vari\u00e1veis de evid\u00eancia, e a lista de valores observados para elas e Y as vari\u00e1veis n\u00e3o observadas restantes.</p>"},{"location":"bayes_rule/","title":"Regra de Bayes\u200b","text":"<p>O Teorema de Bayes \u00e9 uma f\u00f3rmula matem\u00e1tica que ajuda a determinar a probabilidade condicional de um evento com base no conhecimento pr\u00e9vio e em novas evid\u00eancias. Ele ajusta as probabilidades quando surgem novas informa\u00e7\u00f5es e ajuda a tomar melhores decis\u00f5es em situa\u00e7\u00f5es incertas. \u00c9 usada para determinar a probabilidade condicional do evento A quando o evento B j\u00e1 ocorreu. [6] O enunciado geral do teorema de Bayes \u00e9: \u201cA probabilidade condicional de um evento A, dada a ocorr\u00eancia de outro evento B, \u00e9 igual ao produto do evento B, dado A e a probabilidade de A dividida pela probabilidade do evento B.\u201d [6]</p>"},{"location":"bayes_rule/#formula","title":"F\u00f3rmula","text":"<p>P(A|B) = P(B|A) \u22c5 P(A) / P(B)</p> <ul> <li>P(A) e P(B) s\u00e3o as probabilidades dos eventos A e B. Al\u00e9m disso, P(B) nunca \u00e9 igual a zero.</li> <li>P(A|B) \u00e9 a probabilidade do evento A quando o evento B acontece.</li> <li>P(B|A) \u00e9 a probabilidade do evento B quando A acontece.</li> </ul> <p>Para encontrar causa e efeito:</p> <p>P(causa|efeito) = P(efeito|causa) \u22c5 P(causa) / P(efeito)</p> <ul> <li>A probabilidade condicional P(efeito | causa) quantifica a rela\u00e7\u00e3o na dire\u00e7\u00e3o causal. </li> <li>Enquanto P(causa | efeito) descreve a dire\u00e7\u00e3o do diagn\u00f3stico.</li> </ul> <p>Observa\u00e7\u00e3o: O conhecimento de diagn\u00f3stico geralmente \u00e9 mais fr\u00e1gil do que o conhecimento causal.</p> <p>Forma geral com normaliza\u00e7\u00e3o:</p> <p>P(Y|X) = \u03b1P(X|Y)P(Y)</p> <ul> <li>\u03b1 \u00e9 a constante de normaliza\u00e7\u00e3o necess\u00e1ria para fazer com que as entradas em P(Y|X) somem 1.</li> <li>Usado para evitar a avalia\u00e7\u00e3o da probabilidade anterior da evid\u00eancia, calculando uma probabilidade posterior para cada valor da vari\u00e1vel de consulta e, em seguida, normalizando os resultados.</li> </ul> <p>Combina\u00e7\u00e3o de evid\u00eancias:</p> <p>Se tem duas ou mais pe\u00e7as de evid\u00eancia:</p> <p>P(A|B \u2227 C) = \u03b1P(B \u2227 C|A)P(A)</p> <p>Propriedade de independ\u00eancia condicional de A e B dada C:</p> <p>P(B \u2227 C|A) = P(B|A)P(C|A)</p> <p>Equa\u00e7\u00e3o de probabilidade de independ\u00eancia pode ser inserida na equa\u00e7\u00e3o acima:</p> <p>P(A|B \u2227 C) = \u03b1P(B|A)P(C|A)P(A)</p> <p>Defini\u00e7\u00e3o geral de independ\u00eancia condicional entre duas vari\u00e1veis X, Y dada uma vari\u00e1vel Z:</p> <p>P(X,Y|Z) = P(X|Z)P(Y|Z)</p> <p>Nota\u00e7\u00e3o de independ\u00eancia absoluta:</p> <ul> <li>P(X|Y,Z)=P(X|Z)</li> <li>P(Y|X,Z)=P(Y|Z)</li> </ul> <p>Ambos s\u00e3o equivalentes.</p> <p>Forma completa do dom\u00ednio:</p> <p>P(B,C,A) = P(B,C|A)P(A) = P(B|A)P(C|A)P(A)</p> <p>Aplica\u00e7\u00f5es da regra de Bayes:</p> <ul> <li>Testes m\u00e9dicos: Encontrar a probabilidade real de ter uma doen\u00e7a ap\u00f3s um teste positivo.</li> <li>Filtros de spam: Verificar se um e-mail \u00e9 spam com base em palavras-chave.</li> <li>Previs\u00e3o do tempo: Atualiza\u00e7\u00e3o da chance de chuva com base em novos dados.</li> <li>IA e aprendizado de m\u00e1quina: Usado em classificadores Na\u00efve Bayes para prever resultados.</li> </ul>"},{"location":"bayes_rule/#modelo-de-bayes-ingenuo","title":"Modelo de Bayes Ing\u00eanuo\u200b","text":"<p>Os classificadores Naive Bayes s\u00e3o algoritmos de aprendizado de m\u00e1quina supervisionados usados para tarefas de classifica\u00e7\u00e3o, com base no Teorema de Bayes para encontrar probabilidades. A ideia principal por tr\u00e1s do classificador Naive Bayes \u00e9 usar o Teorema de Bayes para classificar os dados com base nas probabilidades de diferentes classes, considerando os recursos dos dados. Ele \u00e9 usado principalmente na classifica\u00e7\u00e3o de textos de alta dimens\u00e3o. [7]</p> <p>A distribui\u00e7\u00e3o conjunta completa pode ser escrita como\u200b:</p> \\[ P(\\text{Causa}, \\text{Efeito}_1, \\dots, \\text{Efeito}_n) = P(\\text{Causa}) \\cdot \\prod_{i} P(\\text{Efeito}_i \\mid \\text{Causa}) \\] <ul> <li>\\(P(\\text{Causa})\\): Probabilidade do evento \"Causa\" ocorrer.</li> <li>\\(P(\\text{Efeito}_i \\mid \\text{Causa})\\): Probabilidade condicional de cada efeito dado que a causa ocorreu.</li> <li>Multiplica\u00e7\u00e3o dos termos: Assume que os efeitos \\( \\text{Efeito}_1, ..., \\text{Efeito}_n \\) s\u00e3o independentes condicionalmente \u00e0 causa.</li> </ul> <p>Para usar um modelo Bayes ing\u00eanuo, podemos aplicar a equa\u00e7\u00e3o anterior para obter a probabilidade da causa com base em alguns efeitos observados. Chame os efeitos observados de E=e, enquanto as demais vari\u00e1veis de efeito Y n\u00e3o s\u00e3o observadas.</p> \\[ P(\\text{Causa} \\mid e) = \\alpha \\sum_{y} P(\\text{Causa}, e, y) \\] <ul> <li>\\( P(\\text{Causa} \\mid e) \\): Probabilidade da Causa ap\u00f3s observar \\( e \\).</li> <li>\\( P(\\text{Causa}, e, y) \\): Probabilidade conjunta da Causa, da evid\u00eancia \\( e \\) e de uma vari\u00e1vel oculta \\( y \\).</li> <li>Marginaliza\u00e7\u00e3o: A soma sobre \\( y \\) nos permite obter a probabilidade total, levando em conta todas as possibilidades dessa vari\u00e1vel oculta.</li> <li>Normaliza\u00e7\u00e3o: \\( \\alpha \\) \u00e9 um fator de escala que garante que a soma de todas as probabilidades seja 1.</li> </ul> <p>Finalmente temos:</p> \\[ P(\\text{Cause} \\mid e) = \\alpha \\sum_{y} P(\\text{Cause}) P(y \\mid \\text{Cause}) \\prod_{j} P(e_j \\mid \\text{Cause}) \\] <p>Como \\( \\sum_{y} P(y \\mid \\text{Cause}) = 1 \\), a equa\u00e7\u00e3o pode ser simplificada para:</p> \\[ P(\\text{Cause} \\mid e) = \\alpha P(\\text{Cause}) \\prod_{j} P(e_j \\mid \\text{Cause}) \\] <ul> <li>\\( P(\\text{Cause} \\mid e) \\): Probabilidade da causa ap\u00f3s observar a evid\u00eancia.</li> <li>\\( P(\\text{Cause}) \\): Probabilidade inicial (prior) da causa.</li> <li>\\( P(y \\mid \\text{Cause}) \\): Probabilidade da vari\u00e1vel oculta \\( y \\) dado a causa.</li> <li>\\( P(e_j \\mid \\text{Cause}) \\): Probabilidade condicional de cada evid\u00eancia \\( e_j \\) dado a causa.</li> <li>\\( \\alpha \\): Fator de normaliza\u00e7\u00e3o para garantir que as probabilidades somem 1.</li> </ul>"},{"location":"bayes_rule/#por-que-ele-e-chamado-de-ingenuo","title":"Por que ele \u00e9 chamado de ing\u00eanuo","text":"<ul> <li>Ele \u00e9 chamado de ing\u00eanuo porque presume que a presen\u00e7a de um recurso n\u00e3o afeta outros recursos. [7]</li> <li>Pressup\u00f5e que todos os recursos contribuem igualmente para o resultado. [8]</li> <li>Muitas vezes \u00e9 usada como uma suposi\u00e7\u00e3o simplificadora;\u200b nos casos em que as vari\u00e1veis \u200b\u200bde \u201cefeito\u201d n\u00e3o s\u00e3o estritamente independente dada a vari\u00e1vel causa.\u200b [1]</li> </ul>"},{"location":"bayes_rule/#suposicao-de-bayes-ingenuo","title":"Suposi\u00e7\u00e3o de Bayes Ing\u00eanuo\u200b","text":"<p>O pressuposto fundamental do Naive Bayes \u00e9 que cada recurso faz uma an\u00e1lise:</p> <ul> <li>Independ\u00eancia de recursos: Isso significa que, quando estamos tentando classificar algo, presumimos que cada recurso (ou informa\u00e7\u00e3o) nos dados n\u00e3o afeta nenhum outro recurso. [7]</li> <li>Os recursos cont\u00ednuos s\u00e3o distribu\u00eddos normalmente: Se um recurso for cont\u00ednuo, presume-se que ele seja normalmente distribu\u00eddo em cada classe. [7]</li> <li>Os recursos discretos t\u00eam distribui\u00e7\u00f5es multinomiais: Se um recurso for discreto, presume-se que ele tenha uma distribui\u00e7\u00e3o multinomial dentro de cada classe. [7]</li> <li>Os recursos s\u00e3o igualmente importantes: presume-se que todos os recursos contribuam igualmente para a previs\u00e3o do r\u00f3tulo da classe. [7]</li> <li>N\u00e3o h\u00e1 dados ausentes: Os dados n\u00e3o devem conter valores ausentes. [7]</li> </ul>"},{"location":"bayes_rule/#aplicacoes-do-bayes-ingenuo","title":"Aplica\u00e7\u00f5es do Bayes Ing\u00eanuo\u200b","text":"<ul> <li>Filtragem de e-mails de spam: Classifica e-mails como spam ou n\u00e3o spam com base em recursos. [7]</li> <li>Classifica\u00e7\u00e3o de texto: Usado na an\u00e1lise de sentimentos, categoriza\u00e7\u00e3o de documentos e classifica\u00e7\u00e3o de t\u00f3picos. [7]</li> <li>Diagn\u00f3stico m\u00e9dico: ajuda a prever a probabilidade de uma doen\u00e7a com base nos sintomas. [7]</li> <li>Pontua\u00e7\u00e3o de cr\u00e9dito: Avalia a capacidade de cr\u00e9dito de indiv\u00edduos para aprova\u00e7\u00e3o de empr\u00e9stimos. [7]</li> <li>Previs\u00e3o do tempo: Classifica as condi\u00e7\u00f5es clim\u00e1ticas com base em v\u00e1rios fatores. [7]</li> </ul>"},{"location":"bayes_rule/#tipos-de-bayes-ingenuo","title":"Tipos de Bayes Ing\u00eanuo\u200b","text":"<ul> <li> <p>Gaussiano Naive Bayes: No Gaussian Naive Bayes, presume-se que os valores cont\u00ednuos associados a cada recurso sejam distribu\u00eddos de acordo com uma distribui\u00e7\u00e3o gaussiana. Uma distribui\u00e7\u00e3o gaussiana tamb\u00e9m \u00e9 chamada de distribui\u00e7\u00e3o normal. [7]</p> </li> <li> <p>Multinomial Naive Bayes: O Multinomial Naive Bayes \u00e9 usado quando os recursos representam a frequ\u00eancia de termos (como contagem de palavras) em um documento. \u00c9 comumente aplicado na classifica\u00e7\u00e3o de textos, em que as frequ\u00eancias de termos s\u00e3o importantes. [7] Essa variante \u00e9 \u00fatil ao usar dados discretos, como contagens de frequ\u00eancia, e \u00e9 normalmente aplicada em casos de uso de processamento de linguagem natural, como classifica\u00e7\u00e3o de spam. [8]</p> </li> <li> <p>Bernoulli Naive Bayes: O Bernoulli Naive Bayes lida com recursos bin\u00e1rios, em que cada recurso indica se uma palavra aparece ou n\u00e3o em um documento. Ele \u00e9 adequado para cen\u00e1rios em que a presen\u00e7a ou aus\u00eancia de termos \u00e9 mais relevante do que sua frequ\u00eancia. Ambos os modelos s\u00e3o amplamente usados em tarefas de classifica\u00e7\u00e3o de documentos. [7]</p> </li> </ul>"},{"location":"bayesian_network/","title":"Redes Bayesianas\u200b","text":"<p>Uma rede bayesiana \u00e9 um modelo gr\u00e1fico que exibe vari\u00e1veis em um conjunto de dados e as independ\u00eancias probabil\u00edsticas ou condicionais entre elas. As rela\u00e7\u00f5es causais entre os n\u00f3s podem ser representadas por uma rede bayesiana; entretanto, os links na rede n\u00e3o representam necessariamente causa e efeito diretos. Por exemplo, uma rede bayesiana pode ser usada para calcular a probabilidade de um paciente ter uma doen\u00e7a espec\u00edfica, dada a presen\u00e7a ou aus\u00eancia de determinados sintomas e outros dados relevantes, se as independ\u00eancias probabil\u00edsticas entre os sintomas e a doen\u00e7a, conforme exibidas no gr\u00e1fico, forem verdadeiras. As redes s\u00e3o muito robustas quando faltam informa\u00e7\u00f5es e fazem a melhor previs\u00e3o poss\u00edvel usando qualquer informa\u00e7\u00e3o presente. [9]</p>"},{"location":"bayesian_network/#usos-de-redes-bayesianas","title":"Usos de redes bayesianas","text":"<ul> <li>Sele\u00e7\u00e3o de oportunidades de empr\u00e9stimo com baixo risco de inadimpl\u00eancia. [9]</li> <li>Estimativa de quando o equipamento precisar\u00e1 de manuten\u00e7\u00e3o, pe\u00e7as ou substitui\u00e7\u00e3o, com base na entrada do sensor e nos registros existentes. [9]</li> <li>Resolu\u00e7\u00e3o de problemas de clientes por meio de ferramentas de solu\u00e7\u00e3o de problemas on-line. [9]</li> <li>Diagnosticar e solucionar problemas de redes de telefonia celular em tempo real. [9]</li> <li>Avaliar os poss\u00edveis riscos e recompensas de projetos de pesquisa e desenvolvimento para concentrar os recursos nas melhores oportunidades. [9]</li> </ul>"},{"location":"bayesian_network/#formula","title":"F\u00f3rmula","text":"\\[ P(x_1, x_2, \\dots, x_n) = \\prod_{i=1}^{n} P(x_i \\mid \\text{parents}(X_i)) \\] <ul> <li>Probabilidade conjunta das vari\u00e1veis \\( X_1, \\dots, X_n \\) pode ser fatorada como o produto das probabilidades condicionais de cada vari\u00e1vel \\( X_i \\), dado o conjunto de seus pais no grafo de depend\u00eancia.</li> <li>Aqui parents(Xi) denota os valores de Parents(Xi) que aparecem em \\( X_1, \\dots, X_n \\), cada entrada na distribui\u00e7\u00e3o conjunta \u00e9 representada pelo produto dos elementos apropriados das distribui\u00e7\u00f5es condicionais locais na rede de Bayes.\u200b</li> <li>Suponha que uma rede de Bayes contenha \\( n \\) vari\u00e1veis \\( X_1, \\dots, X_n \\). Uma entrada gen\u00e9rica na distribui\u00e7\u00e3o conjunta \u00e9 representada por \\(P(X_1 = x_1 \\wedge \\dots \\wedge X_n = x_n)\\). Ou, de forma abreviada \\(P(x_1, \\dots, x_n)\\).</li> </ul> <p>Exemplo de uso:</p> <p>P(j,m,a,\u00acb,\u00ace) = P(j|a)P(m|a)P(a|\u00acb\u2227\u00ace)P(\u00acb)P(\u00ace) = 0.90 \u00d7 0.70 \u00d7 0.01 \u00d7 0.999 \u00d7 0.998 = 0.00628</p> <p>Os n\u00fameros que entram nas distribui\u00e7\u00f5es condicionais locais \\( \\theta(x_i \\mid \\text{parents}(X_i)) \\) s\u00e3o exatamente as probabilidades condicionais \\(P(x_i \\mid \\text{parents}(X_i))\\) impl\u00edcitas na distribui\u00e7\u00e3o conjunta que podem ser calculadas a partir da distribui\u00e7\u00e3o conjunta da seguinte forma. [1]</p> \\[ P(x_i \\mid \\text{parents}(X_i)) \\equiv \\frac{P(x_i, \\text{parents}(X_i))}{P(\\text{parents}(X_i))} \\] <p>Que pode ser expressa como:</p> \\[ P(x_i \\mid \\text{parents}(X_i)) = \\frac{\\sum_{y} P(x_i, \\text{parents}(X_i), y)} {\\sum_{x'_i, y} P(x'_i, \\text{parents}(X_i), y)} \\] <ul> <li>Em que y representa os valores de todas as vari\u00e1veis que n\u00e3o sejam Xi e seus pais.</li> <li>A partir dessa \u00faltima linha, \u00e9 poss\u00edvel provar que \\(P(x_i \\mid \\text{parents}(X_i))\\) = \\( \\theta(x_i \\mid \\text{parents}(X_i)) \\)</li> </ul> <p>Levando em conta estes dois pontos, pode-se dizer que:</p> \\[ P(x_1, \\dots, x_n) = \\prod_{i=1}^{n} P(x_i \\mid \\text{parents}(X_i)) \\]"},{"location":"bayesian_network/#construcao-de-redes-bayesianas","title":"Constru\u00e7\u00e3o de redes Bayesianas","text":"<p>Primeiro, reescrevemos as entradas na distribui\u00e7\u00e3o conjunta em termos de probabilidade condicional, usando a regra do produto. [1]</p> \\[ P(x_1, \\dots, x_n) = P(x_n \\mid x_{n-1}, \\dots, x_1) P(x_{n-1}, \\dots, x_1) \\] <p>Em seguida, repetimos o processo, reduzindo cada probabilidade conjunta a uma probabilidade condicional e a uma probabilidade conjunta em um conjunto menor de vari\u00e1veis. [1]</p> \\[ P(x_1, \\dots, x_n) = P(x_n \\mid x_{n-1}, \\dots, x_1) P(x_{n-1} \\mid x_{n-2}, \\dots, x_1) \\dots P(x_2 \\mid x_1) P(x_1) \\] <p>Ou, de forma compacta:</p> \\[ P(x_1, \\dots, x_n) = \\prod_{i=1}^{n} P(x_i \\mid x_{i-1}, \\dots, x_1) \\] <p>Essa identidade \u00e9 chamada de regra da cadeia. Ela \u00e9 v\u00e1lida para qualquer conjunto de vari\u00e1veis aleat\u00f3rias. Comparando-a com a equa\u00e7\u00e3o anterior, vemos que a especifica\u00e7\u00e3o da distribui\u00e7\u00e3o conjunta \u00e9 equivalente \u00e0 afirma\u00e7\u00e3o geral de que, para cada vari\u00e1vel \\( X_i \\) na rede. [1]</p> \\[ P(X_i \\mid X_{i-1}, \\dots, X_1) = P(X_i \\mid \\text{Parents}(X_i)) \\] <p>Isso s\u00f3 se aplica se \\(\\text{Parents}(X_i) \\subseteq \\{ X_{i-1}, \\dots, X_1 \\}\\). Essa \u00faltima condi\u00e7\u00e3o \u00e9 satisfeita ao numerar os n\u00f3s da ordem topol\u00f3gica em ordem topol\u00f3gica, ou seja, em qualquer ordem consistente com a estrutura do gr\u00e1fico direcionado. [1]</p> <p>Metodologia:</p> <ul> <li>N\u00f3s: Primeiro, determine o conjunto de vari\u00e1veis necess\u00e1rias para modelar o dom\u00ednio. Agora, ordene-as, \\(\\{X_1, \\dots, X_n\\}\\). Qualquer ordem funcionar\u00e1, mas a rede resultante ser\u00e1 mais compacta se as vari\u00e1veis forem ordenadas de forma que as causas precedam os efeitos. [1]</li> <li> <p>Links: De i = 1 at\u00e9 n fa\u00e7a:</p> <ul> <li>Escolha um conjunto m\u00ednimo de pais para \\( X_i \\) de \\(X_1, \\dots, X_{i-1}\\), de modo que a equa\u00e7\u00e3o \\(P(X_i \\mid X_{i-1}, \\dots, X_1) = P(X_i \\mid \\text{Parents}(X_i))\\) seja satisfeita. [1]</li> <li>Para cada pai, insira um link do pai para \\( X_i \\). [1]</li> <li>CPTs: Escreva a tabela de probabilidade condicional, \\(P(X_i \\mid \\text{Parents}(X_i))\\). [1]</li> </ul> </li> <li> <p>Como cada n\u00f3 est\u00e1 conectado apenas aos n\u00f3s anteriores, este m\u00e9todo de constru\u00e7\u00e3o garante que a rede \u00e9 ac\u00edclica.</p> </li> <li>Outra propriedade importante das redes de Bayes \u00e9 que elas n\u00e3o cont\u00eam valores de probabilidade redundantes;.</li> <li>Se n\u00e3o houver redund\u00e2ncia, ent\u00e3o n\u00e3o h\u00e1 chance de inconsist\u00eancia.</li> </ul>"},{"location":"bayesian_network/#independencia","title":"Independ\u00eancia","text":"<p>Propriedades de independ\u00eancia:</p> <ul> <li>Propriedade n\u00e3o-descendentes: Cada vari\u00e1vel \u00e9 condicionalmente independente de seus n\u00e3o descendentes, dados seus genitores.\u200b</li> <li>Cobertor de Markov: uma vari\u00e1vel \u00e9 condicionalmente independente de todos os outros n\u00f3s da rede, dados seus genitores, filhos e genitores de filhos.</li> </ul> <p>Representa\u00e7\u00e3o de distribui\u00e7\u00f5es condicionais:</p> <ul> <li>N\u00f3s determin\u00edsticos: Um n\u00f3 determin\u00edstico tem seu valor especificado exatamente pelos valores de seus pais, sem incerteza;\u200b</li> <li>Independ\u00eancia de contexto espec\u00edfico (CSI, context-specific Independence): Uma distribui\u00e7\u00e3o condicional exibe CSI se uma vari\u00e1vel \u00e9 condicionalmente independente de alguns de seus pais dados certos valores de outros.\u200b</li> <li>OR-ruidoso: O modelo OR ruidoso permite incerteza sobre a capacidade de cada genitor de causar o filho ser verdadeiro.</li> </ul> <p>Regra geral:</p> \\[ P(x_i \\mid \\text{parents}(X_i)) = 1 - \\prod_{\\{ j : X_j = \\text{true} \\}} q_j \\]"},{"location":"bayesian_network/#variaveis-continuas","title":"Vari\u00e1veis cont\u00ednuas\u200b","text":"<p>Para lidar com vari\u00e1veis cont\u00ednuas existem algumas alternativas:\u200b</p> <ul> <li>Discretiza\u00e7\u00e3o: Dividir os valores poss\u00edveis em intervalos fixos, por exemplo, faixas de temperatura (&lt;0\u00b0C, 0\u00b0C\u2212100\u00b0C, e &gt;100\u00b0C);\u200b</li> <li>Distribui\u00e7\u00f5es probabil\u00edsticas: Outra abordagem \u00e9 definir uma vari\u00e1vel cont\u00ednua usando uma das fam\u00edlias padr\u00e3o de fun\u00e7\u00f5es de densidade de probabilidade, como a distribui\u00e7\u00e3o Gaussiana                       ;\u200b</li> <li>N\u00e3o param\u00e9trica: Define a distribui\u00e7\u00e3o condicional implicitamente com uma cole\u00e7\u00e3o de inst\u00e2ncias, cada uma contendo valores das vari\u00e1veis \u200b\u200bgenitoras e filho.</li> </ul> <p>Para lidar com redes hibridas, precisamos aprender a converter vari\u00e1veis genitoras cont\u00ednuas em vari\u00e1veis filhos discretas e vice versa.</p> <p>Para trazer a informa\u00e7\u00e3o de genitores discretos em filhos cont\u00ednuos podemos utilizar estrat\u00e9gias como distribui\u00e7\u00e3o condicional linear-gaussiana em que o filho tem uma distribui\u00e7\u00e3o gaussiana cuja m\u00e9dia \u00b5 varia linearmente com o valor do genitor e cujo desvio padr\u00e3o \u03c3 \u00e9 fixo.\u200b</p> <p>Para trazer informa\u00e7\u00f5es de genitores cont\u00ednuos em filhos discretos podemos usar fun\u00e7\u00f5es de limiariza\u00e7\u00e3o como a integral da distribui\u00e7\u00e3o normal at\u00e9 o valor x.</p>"},{"location":"conclusions/","title":"Conclus\u00e3o","text":"<p>Entendendo as bases das Redes Bayesianas, Modelo Oculto de Markov e Filtros de Kalman ademas das f\u00f3rmulas estaduais que eles usam, as situa\u00e7\u00f5es em que podem ser aplicadas e como essas f\u00f3rmulas podem ser alteradas para abranger certas situa\u00e7\u00f5es j\u00e1 somos capazes de fazer previs\u00f5es com um certo n\u00edvel de precis\u00e3o mesmo quando partes do mundo s\u00e3o desconhecidas.</p>"},{"location":"decision/","title":"Teoria de Decis\u00e3o","text":""},{"location":"decision/#teoria-da-probabilidade","title":"Teoria da probabilidade","text":"<p>\u00c9 um ramo avan\u00e7ado da matem\u00e1tica que lida com a medi\u00e7\u00e3o da probabilidade de ocorr\u00eancia de eventos. Ela fornece ferramentas para analisar situa\u00e7\u00f5es que envolvem incerteza e ajuda a determinar a probabilidade de certos resultados. Essa teoria usa os conceitos de vari\u00e1veis aleat\u00f3rias, espa\u00e7o amostral, distribui\u00e7\u00f5es de probabilidade e outros para determinar o resultado de qualquer situa\u00e7\u00e3o. [3] Esta ser\u00e1 nossa principal ferramenta para lidar com os graus de cren\u00e7a. [1]</p>"},{"location":"decision/#abordagens-na-teoria-da-probabilidade","title":"Abordagens na teoria da probabilidade","text":"<p>Probabilidade te\u00f3rica: A probabilidade te\u00f3rica trata com suposi\u00e7\u00f5es para evitar a repeti\u00e7\u00e3o invi\u00e1vel ou dispendiosa de experimentos. [3] A f\u00f3rmula de probabilidade te\u00f3rica usada para calcular a probabilidade de um evento A \u00e9: P(A) = (N\u00famero de resultados favor\u00e1veis ao Evento A) / (N\u00famero de todos os resultados poss\u00edveis) [3]</p> <p>Probabilidade experimental: A probabilidade experimental \u00e9 encontrada por meio da realiza\u00e7\u00e3o de uma s\u00e9rie de experimentos e da observa\u00e7\u00e3o de seus resultados. Esses experimentos aleat\u00f3rios tamb\u00e9m s\u00e3o conhecidos como tentativas. A f\u00f3rmula experimental de probabilidade para um evento A \u00e9: P(E) = (N\u00famero de vezes que o evento A ocorreu) / (N\u00famero total de tentativas) [3]</p> <p>Probabilidade subjetiva: Refere-se \u00e0 probabilidade de ocorr\u00eancia de um evento, conforme estimada por um indiv\u00edduo com base em suas cren\u00e7as, experi\u00eancias, intui\u00e7\u00e3o ou conhecimento pessoal, e n\u00e3o em dados estat\u00edsticos objetivos ou modelos matem\u00e1ticos formais. [3]</p>"},{"location":"decision/#fundamentos-da-teoria-da-probabilidade","title":"Fundamentos da teoria da probabilidade","text":"<ul> <li> <p>Experimento aleat\u00f3rio: Qualquer evento que possa ser repetido v\u00e1rias vezes e cujo resultado n\u00e3o seja prejudicado pela repeti\u00e7\u00e3o \u00e9 chamado de experimento aleat\u00f3rio. [3]</p> </li> <li> <p>Espa\u00e7o amostral: O conjunto de todos os resultados poss\u00edveis para qualquer experimento aleat\u00f3rio \u00e9 chamado de espa\u00e7o amostral. [3]</p> </li> <li> <p>Evento: O resultado de qualquer experimento \u00e9 chamado de evento. [3]</p> <ul> <li>Eventos independentes: Eventos cujos resultados n\u00e3o s\u00e3o afetados pelos resultados de outros eventos futuros e/ou passados. [3]</li> <li>Eventos dependentes: Eventos cujos resultados s\u00e3o afetados pelo resultado de outros eventos. [3]</li> <li>Eventos mutuamente exclusivos: Eventos que n\u00e3o podem ocorrer simultaneamente. [3]</li> <li>Eventos igualmente prov\u00e1veis: Eventos que t\u00eam a mesma chance ou probabilidade de acontecer [3]</li> </ul> </li> </ul>"},{"location":"decision/#formulas","title":"F\u00f3rmulas","text":"<ul> <li>F\u00f3rmula da probabilidade te\u00f3rica: (N\u00famero de resultados favor\u00e1veis) / (N\u00famero de resultados totais)</li> <li>F\u00f3rmula de probabilidade emp\u00edrica: (N\u00famero de vezes que o evento A ocorreu) / (N\u00famero total de tentativas)</li> <li>Regra de adi\u00e7\u00e3o de probabilidade: P(A \u222a B) = P(A) + P(B) - P(A\u2229B)</li> <li>Regra complementar de probabilidade: P(A') = 1 - P(A)</li> <li>Eventos independentes: P(A\u2229B) = P(A) \u22c5 P(B)</li> <li>Probabilidade condicional: P(A | B) = P(A\u2229B) / P(B)</li> <li>Teorema de Bayes: P(A | B) = P(B | A) \u22c5 P(A) / P(B)</li> </ul>"},{"location":"decision/#teoria-da-decisao","title":"Teoria da decis\u00e3o","text":"<p>Combina o valor de utilidade dado pela teoria da utilidade de um estado junto com a probabilidade desse estado ocorrer, depois faz decis\u00f5es levando estes dois fatores em conta. A ideia fundamental da teoria da decis\u00e3o \u00e9 que um agente \u00e9 racional se e somente se ele escolher a a\u00e7\u00e3o que produz a maior utilidade esperada, calculada a m\u00e9dia de todos os resultados poss\u00edveis da a\u00e7\u00e3o. Isso \u00e9 chamado de princ\u00edpio da utilidade m\u00e1xima esperada (MEU). [1]</p>"},{"location":"hidden_markov/","title":"Modelo Oculto de Markov","text":"<p>\u00c9 um modelo estat\u00edstico usado para descrever a rela\u00e7\u00e3o probabil\u00edstica entre uma sequ\u00eancia de observa\u00e7\u00f5es e uma sequ\u00eancia de estados ocultos. Ike \u00e9 frequentemente usado em situa\u00e7\u00f5es em que o sistema ou processo subjacente que gera as observa\u00e7\u00f5es \u00e9 desconhecido ou oculto, da\u00ed o nome \u201cModelo de Markov Oculto\u201d.  [12]</p> <p>Um HMM consiste em dois tipos de vari\u00e1veis: estados ocultos e observa\u00e7\u00f5es.</p> <ul> <li>Os estados ocultos s\u00e3o as vari\u00e1veis subjacentes que geram os dados observados, mas n\u00e3o s\u00e3o diretamente observ\u00e1veis. [12]</li> <li>As observa\u00e7\u00f5es s\u00e3o as vari\u00e1veis que s\u00e3o medidas e observadas. [12]</li> </ul> <p>A rela\u00e7\u00e3o entre os estados ocultos e as observa\u00e7\u00f5es \u00e9 modelada usando uma distribui\u00e7\u00e3o de probabilidade. O modelo de Markov oculto (HMM) \u00e9 a rela\u00e7\u00e3o entre os estados ocultos e as observa\u00e7\u00f5es usando dois conjuntos de probabilidades: as probabilidades de transi\u00e7\u00e3o e as probabilidades de emiss\u00e3o. [12]</p> <ul> <li>As probabilidades de transi\u00e7\u00e3o descrevem a probabilidade de transi\u00e7\u00e3o de um estado oculto para outro. [12]</li> <li>As probabilidades de emiss\u00e3o descrevem a probabilidade de observar uma sa\u00edda em um estado oculto. [12]</li> </ul>"},{"location":"hidden_markov/#algoritmo-do-modelo-de-markov-oculto","title":"Algoritmo do modelo de Markov oculto","text":"<ul> <li>Etapa 1: Definir o espa\u00e7o de estado e o espa\u00e7o de observa\u00e7\u00e3o: O espa\u00e7o de estado \u00e9 o conjunto de todos os estados ocultos poss\u00edveis, e o espa\u00e7o de observa\u00e7\u00e3o \u00e9 o conjunto de todas as observa\u00e7\u00f5es poss\u00edveis. [12]</li> <li>Etapa 2: definir a distribui\u00e7\u00e3o do estado inicial: Essa \u00e9 a distribui\u00e7\u00e3o de probabilidade sobre o estado inicial. [12]</li> <li>Etapa 3: definir as probabilidades de transi\u00e7\u00e3o de estado: Essas s\u00e3o as probabilidades de transi\u00e7\u00e3o de um estado para outro. Isso forma a matriz de transi\u00e7\u00e3o, que descreve a probabilidade de passar de um estado para outro. [12]</li> <li>Etapa 4: definir as probabilidades de observa\u00e7\u00e3o: Essas s\u00e3o as probabilidades de gerar cada observa\u00e7\u00e3o de cada estado. Isso forma a matriz de emiss\u00e3o, que descreve a probabilidade de gerar cada observa\u00e7\u00e3o de cada estado. [12]</li> <li>Etapa 5: Treinar o modelo: Os par\u00e2metros das probabilidades de transi\u00e7\u00e3o de estado e as probabilidades de observa\u00e7\u00e3o s\u00e3o estimados usando o algoritmo Baum-Welch ou o algoritmo forward-backward. Isso \u00e9 feito por meio da atualiza\u00e7\u00e3o iterativa dos par\u00e2metros at\u00e9 a converg\u00eancia. [12]</li> <li>Etapa 6: Decodificar a sequ\u00eancia mais prov\u00e1vel de estados ocultos: Com base nos dados observados, o algoritmo de Viterbi \u00e9 usado para calcular a sequ\u00eancia mais prov\u00e1vel de estados ocultos. Isso pode ser usado para prever observa\u00e7\u00f5es futuras, classificar sequ\u00eancias ou detectar padr\u00f5es em dados sequenciais. [12]</li> <li>Etapa 7: Avaliar o modelo: O desempenho do HMM pode ser avaliado por meio de v\u00e1rias m\u00e9tricas, como exatid\u00e3o, precis\u00e3o, recall ou pontua\u00e7\u00e3o F1. [12]</li> </ul>"},{"location":"hidden_markov/#algoritmos-matriciais-simplificados","title":"Algoritmos Matriciais Simplificados\u200b","text":"<p>Probability of a transition from state i to state j</p> \\[ T_{i,j} = P(X_t = j \\mid X_{t-1} = i) \\] <ul> <li>A vari\u00e1vel de estado \\( X_t \\) tem valores denotados por n\u00fameros inteiros 1, . . . ,S.</li> <li>S \u00e9 o n\u00famero de estados poss\u00edveis.</li> <li>O modelo de transi\u00e7\u00e3o \\( P(X_t | X_{t-1}) \\) torna-se uma matriz S\u00d7S T.</li> </ul> <p>Podemos fazer o mesmo com o modelo de sensor;, neste caso, como o valor da vari\u00e1vel de evid\u00eancia \\( E_t \\) \u00e9 conhecida no tempo t, precisamos especificar para cada estado apenas, a probabilidade que o estado faz com que \\( e_t \\) apare\u00e7a, ou seja, \\( P(e_t | X_t = i) \\)para cada estado i. [1]</p> <p>Para tanto, criamos a matriz de observa\u00e7\u00e3o Ot de dimens\u00f5es SxS, uma para cada passo, a i-\u00e9sima entrada diagonal de \\( O_t \\) \u00e9 \\( P(e_t | X_t = i) \\) e as outras entradas s\u00e3o 0.\u200b [1]</p> <p>Equa\u00e7\u00e3o de avan\u00e7o:</p> \\[ f_{1:t+1} = \\alpha O_{t+1} T^\\top f_{1:t} \\] <ul> <li>\\( f_{1:t} \\) \u00e9 a distribui\u00e7\u00e3o para frente at\u00e9 o tempo \\( t \\).</li> <li>\\( T \\) \u00e9 a matriz de transi\u00e7\u00e3o entre estados.</li> <li>\\( O_{t+1} \\) \u00e9 a matriz de observa\u00e7\u00e3o.</li> <li>\\( \\alpha \\) \u00e9 um fator de normaliza\u00e7\u00e3o. \u200b Equa\u00e7\u00e3o regressiva</li> </ul> \\[ b_{k+1:t} = T O_{k+1} b_{k+2:t} \\] <ul> <li>\\( b_{k+1:t} \\) \u00e9 a distribui\u00e7\u00e3o para tr\u00e1s a partir do tempo \\( k+1 \\).</li> <li>\\( T \\) \u00e9 a matriz de transi\u00e7\u00e3o.</li> <li>\\( O_{k+1} \\) \u00e9 a matriz de observa\u00e7\u00e3o no tempo \\( k+1 \\).</li> </ul>"},{"location":"independence/","title":"Independ\u00eancia","text":"<p>Supondo que adicone uma vari\u00e1vel D \u00e0 distribui\u00e7\u00e3o anterior, transformando-se em P(A, B, C, D), para encontrar a rela\u00e7\u00e3o entre ambas as distribui\u00e7\u00f5es e como o valor de P(A, B, C) est\u00e1 relacionado ao valor de P(A, B, C, D) pode ser iniciado usando a regra de produto. [1]</p> <p>P(A,B,C,D) = P(D|A,B,C)P(A,B,C).</p> <p>Agora, assumindo que A, B e C n\u00e3o influenciam o resultado de D pode-se assumir:</p> <p>P(D|A,B,C) = P(D)</p> <p>Depois se deduz:</p> <p>P(A,B,C,D) = P(D)P(A,B,C)</p> <p>A propriedade usada aqui \u00e9 conhecida como independ\u00eancia (independ\u00eancia marginal ou independ\u00eancia absoluta). Pode ser escrita de forma geral assim:</p> <p>Independ\u00eancia de preposi\u00e7\u00f5es (Preposi\u00e7\u00f5es a e b):</p> <ul> <li>P(a|b) = P(a)</li> <li>P(b|a) = P(b)</li> <li>P(a \u2227 b) = P(a)P(b)</li> </ul> <p>Todas essas formas s\u00e3o equivalentes.</p> <p>Independ\u00eancia de vari\u00e1veis (Vari\u00e1veis X e Y):</p> <ul> <li>P(X|Y) = P(X)</li> <li>P(Y|X) = P(Y)</li> <li>P(X,Y) = P(X)P(Y)</li> </ul> <p>Todas essas formas s\u00e3o equivalentes.</p> <p>Identifica\u00e7\u00e3o de independ\u00eancia geralmente \u00e9 baseada em conhecimento de dom\u00ednio. Enquanto independ\u00eancias s\u00e3o muito \u00fateis, reduzindo o tamanho da representa\u00e7\u00e3o de dom\u00ednio e a complexidade do problema de infer\u00eancia no entanto separa\u00e7\u00f5es limpas por independ\u00eancia entre subgrupos de vari\u00e1veis s\u00e3o uy raro encontrar isso porque se existe uma conex\u00e3o n\u00e3o importa qual debil ou indireta entre duas vari\u00e1veis a independ\u00eancia falhar\u00e1. [1]</p>"},{"location":"inference/","title":"Infer\u00eancia","text":"<p>A infer\u00eancia em redes bayesianas envolve a resposta a consultas probabil\u00edsticas sobre a rede. Os tipos mais comuns de consultas s\u00e3o:</p> <ul> <li>Marginaliza\u00e7\u00e3o: Determinar a distribui\u00e7\u00e3o de probabilidade de um subconjunto de vari\u00e1veis, ignorando os valores de todas as outras vari\u00e1veis. [9]</li> <li>Probabilidade condicional: Computa\u00e7\u00e3o da distribui\u00e7\u00e3o de probabilidade de um subconjunto de vari\u00e1veis com base em evid\u00eancias observadas em outras vari\u00e1veis. [9]</li> </ul> <p>Matematicamente, se X s\u00e3o as vari\u00e1veis de consulta e E s\u00e3o as vari\u00e1veis de evid\u00eancia com valores observados e, o objetivo \u00e9 calcular \\(P(X \\mid E = e)\\).</p>"},{"location":"inference/#inferencia-exata","title":"Infer\u00eancia Exata","text":"<p>A infer\u00eancia exata em redes bayesianas \u00e9 um processo fundamental usado para calcular a distribui\u00e7\u00e3o de probabilidade de um subconjunto de vari\u00e1veis, com base em evid\u00eancias observadas em um conjunto de outras vari\u00e1veis. [9]</p>"},{"location":"inference/#metodos-de-inferencia-exata","title":"M\u00e9todos de infer\u00eancia exata","text":""},{"location":"inference/#eliminacao-de-variaveis","title":"Elimina\u00e7\u00e3o de vari\u00e1veis","text":"<p>A elimina\u00e7\u00e3o de vari\u00e1veis \u00e9 uma t\u00e9cnica popular de infer\u00eancia exata que resume sistematicamente as vari\u00e1veis que n\u00e3o s\u00e3o de interesse. O processo envolve a manipula\u00e7\u00e3o e a combina\u00e7\u00e3o dos CPTs da rede para responder \u00e0s consultas de forma eficiente. [9]</p> <p>Etapas:</p> <ul> <li>Fatora\u00e7\u00e3o: Decompor a distribui\u00e7\u00e3o de probabilidade conjunta em um produto de fatores, cada um correspondendo a um CPT na rede. [9]</li> <li>Elimina\u00e7\u00e3o: Eliminar sequencialmente cada vari\u00e1vel n\u00e3o relacionada \u00e0 consulta e n\u00e3o relacionada \u00e0 evid\u00eancia, somando seus valores. Essa etapa reduz a dimensionalidade do problema. [9]</li> <li>Normaliza\u00e7\u00e3o: Ap\u00f3s todas as elimina\u00e7\u00f5es, normalize a distribui\u00e7\u00e3o resultante para garantir que a soma seja igual a um. [9]</li> </ul> <p>Representa\u00e7\u00e3o matem\u00e1tica: Para calcular \\(P(X \\mid E = e)\\), talvez seja necess\u00e1rio somar uma vari\u00e1vel Z que n\u00e3o esteja em X ou E: \\(P(X \\mid E = e) = \\alpha \\sum_Z P(X, Z, E = e)\\) em que \u03b1 \u00e9 uma constante de normaliza\u00e7\u00e3o. [9]</p>"},{"location":"inference/#algoritmo-de-arvore-de-juncao","title":"Algoritmo de \u00e1rvore de jun\u00e7\u00e3o","text":"<p>O Algoritmo de \u00c1rvore de Jun\u00e7\u00e3o, tamb\u00e9m conhecido como Algoritmo de \u00c1rvore de Clique, \u00e9 uma abordagem mais estruturada que converte a Rede Bayesiana em uma estrutura de \u00e1rvore chamada \u201c\u00e1rvore de jun\u00e7\u00e3o\u201d ou \u201c\u00e1rvore de clique\u201d, em que cada n\u00f3 (clique) cont\u00e9m um subconjunto de vari\u00e1veis que formam um subgrafo completo (totalmente conectado) na rede. [9]</p> <p>Etapas:</p> <ul> <li>Triangula\u00e7\u00e3o: Modifique a rede para garantir que todo ciclo de quatro ou mais n\u00f3s tenha uma corda (uma borda que n\u00e3o faz parte do ciclo, mas conecta dois n\u00f3s do ciclo). [9]</li> <li>Constru\u00e7\u00e3o da \u00e1rvore de jun\u00e7\u00e3o: Forme grupos de vari\u00e1veis e organize-os em uma estrutura de \u00e1rvore em que cada borda representa uma declara\u00e7\u00e3o de independ\u00eancia condicional. [9]</li> <li>Passagem de mensagens: Execute uma passagem de mensagens em duas fases (coleta e distribui\u00e7\u00e3o) para propagar informa\u00e7\u00f5es por toda a \u00e1rvore. [9]</li> </ul> <p>Representa\u00e7\u00e3o matem\u00e1tica: Durante a fase de passagem de mensagens, as mensagens (fun\u00e7\u00f5es de probabilidades) s\u00e3o passadas entre os cliques. Se \\( C_i \\) e \\( C_j \\) s\u00e3o dois cliques conectados por um separador, a mensagem de \\( C_i \\) para \\( C_j \\) pode ser calculada como: [9]</p> \\[ M_{i \\rightarrow j}(S) = \\sum_{C_i \\setminus S} \\phi_{C_i}(X_{C_i}) \\] <ul> <li>\\( \\phi_{C_i}(X_{C_i}) \\) \u00e9 o fator ou potencial associado ao clique \\( C_i \\).</li> <li>\\( C_i \\setminus S \\) representa as vari\u00e1veis de \\( C_i \\), excluindo as vari\u00e1veis do separador \\( S \\).</li> <li>\\( M_{i \\rightarrow j}(S) \\) \u00e9 a mensagem passada do clique \\( C_i \\) para o clique \\( C_j \\).</li> </ul>"},{"location":"inference/#propagacao-de-crenca","title":"Propaga\u00e7\u00e3o de cren\u00e7a","text":"<p>A propaga\u00e7\u00e3o de cren\u00e7as (BP) \u00e9 outro m\u00e9todo de infer\u00eancia exata usado principalmente em redes que formam uma estrutura de \u00e1rvore ou que podem ser reestruturadas em uma forma de \u00e1rvore usando o algoritmo de \u00e1rvore de jun\u00e7\u00e3o. Ele envolve a passagem de mensagens entre os n\u00f3s e usa essas mensagens para calcular as probabilidades marginais em cada n\u00f3. [9]</p> <p>Etapas:</p> <ul> <li>Inicializa\u00e7\u00e3o: Cada n\u00f3 inicializa as mensagens com base em suas evid\u00eancias locais e probabilidades condicionais. [9]</li> <li>Passagem de mensagens: Os n\u00f3s enviam e recebem mensagens de e para seus vizinhos. Cada mensagem representa uma cren\u00e7a sobre o estado do remetente, condicionada \u00e0s evid\u00eancias. [9]</li> <li>Atualiza\u00e7\u00e3o da cren\u00e7a: cada n\u00f3 atualiza sua cren\u00e7a com base nas mensagens recebidas e em sua probabilidade inicial. [9]</li> </ul>"},{"location":"inference/#inferencia-aproximada","title":"Infer\u00eancia aproximada","text":"<p>A infer\u00eancia exata em redes bayesianas geralmente \u00e9 impratic\u00e1vel do ponto de vista computacional para redes grandes ou complexas devido ao crescimento exponencial dos requisitos computacionais. Os m\u00e9todos de infer\u00eancia aproximada s\u00e3o uma alternativa vi\u00e1vel, oferecendo estimativas probabil\u00edsticas com custos computacionais significativamente reduzidos. [10]</p>"},{"location":"inference/#metodos-de-inferencia-aproximada","title":"M\u00e9todos de infer\u00eancia aproximada","text":""},{"location":"inference/#metodos-de-monte-carlo","title":"M\u00e9todos de Monte Carlo","text":"<p>Os m\u00e9todos de Monte Carlo usam amostragem aleat\u00f3ria para aproximar sistemas matem\u00e1ticos ou f\u00edsicos complexos. O princ\u00edpio \u00e9 gerar um grande n\u00famero de amostras aleat\u00f3rias de uma distribui\u00e7\u00e3o de probabilidade e usar essas amostras para estimar as propriedades da distribui\u00e7\u00e3o. [10]</p> <p>Esse processo envolve as seguintes etapas:</p> <ul> <li>Definir o problema: Identificar a quantidade a ser estimada (por exemplo, uma integral ou uma probabilidade). [10]</li> <li>Gerar amostras aleat\u00f3rias: Use um gerador de n\u00fameros aleat\u00f3rios para produzir amostras da distribui\u00e7\u00e3o de interesse. [10]</li> <li>Calcular a estimativa: Calcule a quantidade desejada usando as amostras geradas, geralmente calculando a m\u00e9dia dos resultados dos dados amostrados. [10]</li> </ul>"},{"location":"inference/#inferencia-variacional","title":"Infer\u00eancia variacional","text":"<p>A infer\u00eancia variacional transforma o problema da infer\u00eancia em um problema de otimiza\u00e7\u00e3o. Em vez de fazer uma amostragem da distribui\u00e7\u00e3o posterior, ela aproxima a distribui\u00e7\u00e3o por uma distribui\u00e7\u00e3o mais simples e otimiza os par\u00e2metros dessa distribui\u00e7\u00e3o para que fiquem o mais pr\u00f3ximo poss\u00edvel da distribui\u00e7\u00e3o posterior verdadeira. [10]</p> <p>As etapas envolvidas s\u00e3o:</p> <ul> <li>Escolha de uma fam\u00edlia de distribui\u00e7\u00f5es: Selecionar uma fam\u00edlia de distribui\u00e7\u00f5es parametrizadas por par\u00e2metros variacionais. [10]</li> <li>Definir o objetivo variacional: Normalmente, \u00e9 o Limite Inferior de Evid\u00eancia (ELBO), que \u00e9 otimizado para tornar a distribui\u00e7\u00e3o aproximada pr\u00f3xima da posterior verdadeira. [10]</li> <li>Otimizar o ELBO: Use a descida de gradiente ou outras t\u00e9cnicas de otimiza\u00e7\u00e3o para encontrar os melhores par\u00e2metros. [10]</li> </ul> <p>Matematicamente, o ELBO \u00e9 definido como:</p> \\[ \\text{ELBO} = \\mathbb{E}_{q(z)} \\left[ \\log p(x, z) - \\log q(z) \\right] \\] <ul> <li>q(z) \u00e9 a posterioridade aproximada. [10]</li> <li>p(x,z) \u00e9 a probabilidade conjunta dos dados observados x e das vari\u00e1veis latentes z. [10]</li> </ul>"},{"location":"inference/#propagacao-de-crenca-ciclica","title":"Propaga\u00e7\u00e3o de cren\u00e7a ciclica","text":"<p>O Loopy Belief Propagation (LBP) amplia o algoritmo Belief Propagation para redes bayesianas com ciclos (loops). [10]</p> <p>O algoritmo envolve as seguintes etapas:</p> <ul> <li>Inicializa\u00e7\u00e3o: Inicializar as mensagens nas bordas da rede. [10]</li> <li>Transmiss\u00e3o de mensagens: Atualizar iterativamente as mensagens passadas entre os n\u00f3s com base nas mensagens vizinhas. [10]</li> <li>Atualiza\u00e7\u00e3o da cren\u00e7a: calcular as cren\u00e7as (probabilidades marginais) em cada n\u00f3 com base nas mensagens recebidas. [10]</li> </ul> <p>Apesar de seu nome, o LBP nem sempre converge, especialmente em redes com muitos loops. Os problemas de converg\u00eancia podem surgir devido a oscila\u00e7\u00f5es ou diverg\u00eancias nas atualiza\u00e7\u00f5es de mensagens. Quando o LBP converge, ele geralmente fornece boas aproxima\u00e7\u00f5es das probabilidades marginais. [10]</p>"},{"location":"kalman_filter/","title":"Filtros de Kalman","text":"<p>O filtro de Kalman \u00e9 um algoritmo usado para estimar o estado do sistema din\u00e2mico a partir de uma s\u00e9rie de medi\u00e7\u00f5es com ru\u00eddo. Ele \u00e9 amplamente usado em v\u00e1rios campos, como rob\u00f3tica, navega\u00e7\u00e3o e finan\u00e7as, para tarefas como rastreamento e previs\u00e3o. O filtro de Kalman fornece um meio de combinar medi\u00e7\u00f5es observadas com o conhecimento pr\u00e9vio sobre o sistema para produzir estimativas mais precisas. [13]</p> <p>O filtro de Kalman \u00e9 um algoritmo recursivo ideal que estima o estado do sistema din\u00e2mico linear usando a s\u00e9rie de medi\u00e7\u00f5es com ru\u00eddo. Ele opera em duas etapas: previs\u00e3o e atualiza\u00e7\u00e3o. Na etapa de previs\u00e3o, o algoritmo usa a estimativa do estado atual para prever o pr\u00f3ximo estado. Na etapa de atualiza\u00e7\u00e3o, ele incorpora novas medi\u00e7\u00f5es para refinar essa previs\u00e3o, minimizando a m\u00e9dia do erro quadr\u00e1tico. [13]</p> <p>Abordagem passo a passo:</p> <ul> <li>Defina as matrizes: Configure a matriz de transi\u00e7\u00e3o de estado (A), a matriz de controle (B), a matriz de observa\u00e7\u00e3o (H), a covari\u00e2ncia de ru\u00eddo do processo (Q) e a covari\u00e2ncia de ru\u00eddo de medi\u00e7\u00e3o (R). [13]</li> <li>Estado inicial: Inicialize a estimativa de estado e a matriz de covari\u00e2ncia de erro. [13]<ul> <li>Estimativa inicial do estado (X\u2080): Melhor suposi\u00e7\u00e3o do estado inicial.</li> <li>Matriz de covari\u00e2ncia do erro inicial (P\u2080): Define a incerteza inicial da estimativa.</li> </ul> </li> <li>Etapa de previs\u00e3o: Prever o pr\u00f3ximo estado e a covari\u00e2ncia usando o modelo de transi\u00e7\u00e3o de estado. [13]<ul> <li>Previs\u00e3o do estado: \\(\\hat{X}_t^- = A \\hat{X}_{t-1} + B U_t\\).</li> <li>Previs\u00e3o da covari\u00e2ncia: \\(P_t^- = A P_{t-1} A^T + Q\\).</li> </ul> </li> <li>Etapa de atualiza\u00e7\u00e3o: Incorporar a nova medi\u00e7\u00e3o para atualizar a estimativa do estado e a covari\u00e2ncia. [13]<ul> <li> \\[K_t = P_t^- H^T (H P_t^- H^T + R)^{-1}\\] </li> <li> \\[\\hat{X}_t = \\hat{X}_t^- + K_t (Z_t - H \\hat{X}_t^-)\\] </li> <li> \\[P_t = (I - K_t H) P_t^-\\] </li> <li>(\\( K_t \\)) e o Ganho de Kalman.</li> <li>\\(Z_t - H \\hat{X}_t^-\\) \u00e9 a inova\u00e7\u00e3o, ou erro de medi\u00e7\u00e3o.</li> </ul> </li> <li>Repetir: Iterar as etapas de previs\u00e3o e atualiza\u00e7\u00e3o para cada medi\u00e7\u00e3o subsequente. [13]</li> </ul>"},{"location":"references/","title":"Refer\u00eancias","text":"<ul> <li>RUSSELL, S. J.; NORVIG, P. Artificial Intelligence : a Modern Approach. 4th. ed. London: Pearson, 2021. [1]</li> <li>HUBER, F.; CHRISTOPH SCHMIDT-PETRI. Degrees of Belief. [s.l.] Springer Science &amp; Business Media, 2008. [2]</li> <li>Probability Theory. Dispon\u00edvel em: https://www.geeksforgeeks.org/probability-theory/. [3]</li> <li>GEEKSFORGEEKS. Utility-Based Agents in AI. Dispon\u00edvel em: https://www.geeksforgeeks.org/utility-based-agents-in-ai/. [4]</li> <li>GEEKSFORGEEKS. Probabilistic Notation in AI. Dispon\u00edvel em: https://www.geeksforgeeks.org/probabilistic-notation-in-ai/. Acesso em: 1 fev. 2025. [5]</li> <li>GEEKSFORGEEKS. Bayes Theorem - Statement, Formula, Derivation, Examples &amp; FAQs. Dispon\u00edvel em: https://www.geeksforgeeks.org/bayes-theorem/. [6]</li> <li>KUMAR, N. Naive Bayes Classifiers - GeeksforGeeks. Dispon\u00edvel em: https://www.geeksforgeeks.org/naive-bayes-classifiers/. [7]</li> <li>IBM. Naive Bayes. Dispon\u00edvel em: https://www.ibm.com/think/topics/naive-bayes. [8]</li> <li>SPSS Modeler Subscription. Dispon\u00edvel em: https://www.ibm.com/docs/en/spss-modeler/saas?topic=models-bayesian-network-node. [9]</li> <li>GEEKSFORGEEKS. Approximate Inference in Bayesian Networks. Dispon\u00edvel em: https://www.geeksforgeeks.org/approximate-inference-in-bayesian-networks/. [10]</li> <li>GEEKSFORGEEKS. Inference in Temporal Models. Dispon\u00edvel em: https://www.geeksforgeeks.org/inference-in-temporal-models/. Acesso em: 18 fev. 2025. [11]</li> <li>Hidden Markov Model in Machine learning. Dispon\u00edvel em: https://www.geeksforgeeks.org/hidden-markov-model-in-machine-learning/. [12]</li> <li>Kalman Filter in Python. Dispon\u00edvel em: https://www.geeksforgeeks.org/kalman-filter-in-python/. [13]</li> </ul>"},{"location":"references/#referencias-de-codigos","title":"Refer\u00eancias de c\u00f3digos","text":""},{"location":"references/#filtro-de-kalman","title":"Filtro de Kalman","text":"<ul> <li>Kalman Filter in Python. Dispon\u00edvel em: https://www.geeksforgeeks.org/kalman-filter-in-python/.</li> </ul>"},{"location":"states_observations/","title":"Estados e observa\u00e7\u00f5es","text":"<p>Modelos de tempo discreto, nos quais o mundo \u00e9 visto como uma s\u00e9rie de instant\u00e2neos de fatias de tempo ou fatias de tempo. Normalmente, as fatias de tempo s\u00e3o numeradas como 0, 1, 2 e assim por diante, em vez de atribuir tempos espec\u00edficos a elas. Normalmente, sup\u00f5e-se que o intervalo de tempo \u0394 entre as fatias seja o mesmo para cada intervalo. [1]</p> <p>Cada intervalo de tempo em um modelo de probabilidade de tempo discreto cont\u00e9m um conjunto de vari\u00e1veis aleat\u00f3rias, algumas observ\u00e1veis e outras n\u00e3o. Usaremos \\( X_t \\) para denotar o conjunto de vari\u00e1veis de estado no tempo t, que se presume n\u00e3o serem observ\u00e1veis, e \\( E_t \\) para denotar o conjunto de vari\u00e1veis de evid\u00eancia observ\u00e1veis. A observa\u00e7\u00e3o no momento t \u00e9 \\( E_t = e_t \\) para algum conjunto de valores \\( e_t \\). [1]</p> <p>Tamb\u00e9m \u00e9 usada a nota\u00e7\u00e3o \\( a:b \\) para denotar um intervalo de vari\u00e1veis, por exemplo \\(U_{1:3} = \\{ U_1, U_2, U_3 \\}\\).\u200b [1]</p>"},{"location":"temporal_inference/","title":"Infer\u00eancia em modelos temporais","text":"<p>Os modelos temporais desempenham um papel fundamental na an\u00e1lise e previs\u00e3o de fen\u00f4menos dependentes do tempo. Eles capturam rela\u00e7\u00f5es din\u00e2micas e depend\u00eancias entre vari\u00e1veis ao longo do tempo, o que os torna indispens\u00e1veis em \u00e1reas como finan\u00e7as, sa\u00fade e ci\u00eancia clim\u00e1tica. A infer\u00eancia em modelos temporais envolve a estimativa de estados ocultos, par\u00e2metros de modelos e observa\u00e7\u00f5es futuras com base em dados observados. [11]</p>"},{"location":"temporal_inference/#principais-componentes-dos-modelos-temporais","title":"Principais componentes dos modelos temporais:","text":"<ul> <li>Estados: Representam as poss\u00edveis condi\u00e7\u00f5es do sistema em diferentes momentos. [11]</li> <li>Observa\u00e7\u00f5es: S\u00e3o os pontos de dados que s\u00e3o medidos ou percebidos diretamente. [11]</li> <li>Transi\u00e7\u00f5es: S\u00e3o as probabilidades de um estado para outro ao longo do tempo. [11]</li> <li>Emiss\u00f5es: S\u00e3o as probabilidades de observar determinados dados, considerando o estado do sistema. [11]</li> </ul>"},{"location":"temporal_inference/#tipos-de-modelos-temporais","title":"Tipos de modelos temporais","text":"<ul> <li>Modelos autorregressivos (AR): Esses modelos preveem valores futuros com base em uma combina\u00e7\u00e3o linear de valores passados da vari\u00e1vel. A ordem do modelo (denotada como p) indica quantos valores passados s\u00e3o considerados. [11]</li> <li>Modelos de m\u00e9dia m\u00f3vel (MA): Os modelos de m\u00e9dia m\u00f3vel usam erros de previs\u00e3o anteriores em um modelo semelhante a uma regress\u00e3o. Ele pressup\u00f5e que a vari\u00e1vel de sa\u00edda depende linearmente dos valores atuais e de v\u00e1rios valores anteriores dos termos estoc\u00e1sticos (determinados aleatoriamente). [11]</li> <li>M\u00e9dia m\u00f3vel integrada autorregressiva (ARIMA): Os modelos ARIMA combinam termos autorregressivos e termos de m\u00e9dia m\u00f3vel e incluem diferencia\u00e7\u00e3o para tornar a s\u00e9rie temporal estacion\u00e1ria (ou seja, a m\u00e9dia, a vari\u00e2ncia e a autocorrela\u00e7\u00e3o s\u00e3o constantes ao longo do tempo). [11]</li> <li>ARIMA sazonal (SARIMA): Amplia o ARIMA adicionando elementos sazonais ao modelo, que s\u00e3o importantes para conjuntos de dados com padr\u00f5es sazonais claros. [11]</li> <li>Modelos de Markov ocultos (HMMs): S\u00e3o modelos estat\u00edsticos em que o sistema que est\u00e1 sendo modelado \u00e9 considerado um processo de Markov com estados n\u00e3o observados (ocultos). Os HMMs s\u00e3o particularmente conhecidos por sua aplica\u00e7\u00e3o no reconhecimento de padr\u00f5es temporais, como fala, escrita \u00e0 m\u00e3o, reconhecimento de gestos, marca\u00e7\u00e3o de parte da fala e bioinform\u00e1tica. [11]</li> <li>Redes Bayesianas Din\u00e2micas (DBNs): S\u00e3o modelos para dados de s\u00e9ries temporais que generalizam as redes bayesianas para processos din\u00e2micos. Diferentemente das redes bayesianas simples, as DBNs podem representar depend\u00eancias condicionais entre diferentes pontos de tempo. [11]</li> <li>Modelos de espa\u00e7o de estado e filtros de Kalman: Esses s\u00e3o modelos recursivos que estimam o estado do sistema din\u00e2mico linear a partir de uma s\u00e9rie de medi\u00e7\u00f5es com ru\u00eddo. S\u00e3o amplamente usados em engenharia, especialmente para processamento de sinais e sistemas de controle. [11]</li> </ul>"},{"location":"temporal_inference/#metodos-de-inferencia-para-modelos-temporais","title":"M\u00e9todos de infer\u00eancia para modelos temporais","text":""},{"location":"temporal_inference/#filtragem","title":"Filtragem","text":"<p>\u00c9 a tarefa de calcular o estado de cren\u00e7a \\( P(X_t | e_{1:t}) \\), a distribui\u00e7\u00e3o posterior sobre o estado mais recente, considerando todas as evid\u00eancias at\u00e9 o momento. Filtragem \u00e9 o que um agente racional faz para manter o controle do estado atual, de modo que decis\u00f5es racionais possam ser tomadas. [1] Isso \u00e9 particularmente \u00fatil no processamento em tempo real, em que o estado precisa ser estimado \u00e0 medida que novos dados s\u00e3o recebidos. [11]</p> <p>Representa\u00e7\u00e3o matem\u00e1tica:</p> \\[ P(X_t | O_1, O_2, ..., O_t) \\] <ul> <li>\\( X_t \\)  \u00e9 o estado no momento t.</li> <li>\\( O_1, O_2, ..., O_t \\)  s\u00e3o as observa\u00e7\u00f5es at\u00e9 o momento t.</li> </ul> <p>Implementa\u00e7\u00e3o:</p> <ul> <li>Inicializa\u00e7\u00e3o: Comece com uma distribui\u00e7\u00e3o de probabilidade inicial para o primeiro estado. [11]</li> <li>Recurs\u00e3o: Atualizar a probabilidade do estado usando as probabilidades de transi\u00e7\u00e3o e a nova observa\u00e7\u00e3o. [11]</li> </ul> <p>M\u00e9todos comuns de filtragem:</p> <ul> <li>Filtro de Kalman: Um filtro recursivo eficiente para modelos lineares de espa\u00e7o de estado gaussiano que minimiza o erro quadr\u00e1tico m\u00e9dio. [11]</li> <li>Filtro de Kalman estendido (EKF): Uma extens\u00e3o n\u00e3o linear do filtro de Kalman que lineariza os modelos de estado e observa\u00e7\u00e3o em torno da estimativa atual. [11]</li> <li>Filtro de part\u00edculas: Um m\u00e9todo Monte Carlo sequencial que aproxima a distribui\u00e7\u00e3o posterior dos estados ocultos usando amostras ponderadas, adequado para modelos n\u00e3o lineares e n\u00e3o gaussianos. [11]</li> </ul>"},{"location":"temporal_inference/#predicao","title":"Predi\u00e7\u00e3o","text":"<p>Essa \u00e9 a tarefa de calcular a distribui\u00e7\u00e3o posterior sobre o estado futuro, Previs\u00e3o, considerando todas as evid\u00eancias at\u00e9 o momento. Ou seja, queremos calcular \\( P(X_{t+k} | e_{1:t}) \\) para algum k &gt; 0. A previs\u00e3o \u00e9 \u00fatil para avaliar poss\u00edveis cursos de a\u00e7\u00e3o com base em seus resultados esperados. [1]</p> <p>Representa\u00e7\u00e3o matem\u00e1tica:</p> \\[ P(X_{t+k} | O_1, O_2, ..., O_t) \\] <ul> <li>k \u00e9 o n\u00famero de etapas \u00e0 frente do tempo atual t.</li> </ul> <p>Tipos de previs\u00e3o:</p> <ul> <li>Previs\u00e3o de um passo \u00e0 frente: Prev\u00ea a pr\u00f3xima observa\u00e7\u00e3o com base na estimativa do estado atual. [11]</li> <li>Previs\u00e3o em v\u00e1rias etapas: Estende o horizonte de previs\u00e3o ao prever v\u00e1rias observa\u00e7\u00f5es futuras, geralmente usando m\u00e9todos iterativos ou modelando diretamente as depend\u00eancias de v\u00e1rias etapas. [11]</li> </ul> <p>F\u00f3rmula de filtragem e previs\u00e3o:</p> \\[ P(X_{t+1} | e_{1:t+1}) = \\alpha P(e_{t+1} | X_{t+1}) \\sum_{x_t} P(X_{t+1} | x_t, e_{1:t}) P(x_t | e_{1:t}) \\]"},{"location":"temporal_inference/#suavizacao","title":"Suaviza\u00e7\u00e3o","text":"<p>Essa \u00e9 a tarefa de calcular a distribui\u00e7\u00e3o posterior sobre um estado passado, considerando todas as evid\u00eancias at\u00e9 o presente. Ou seja, desejamos calcular \\( P(X_k | e_{1:t}) \\) para algum k tal que 0 \u2264 k &lt; t. A suaviza\u00e7\u00e3o fornece uma estimativa melhor do estado no momento k, pois incorpora mais evid\u00eancias. [1]</p> <p>Representa\u00e7\u00e3o matem\u00e1tica:</p> \\[ P(X_t | O_1, O_2, ..., O_N) \\] <ul> <li>N \u00e9 o n\u00famero total de observa\u00e7\u00f5es.</li> </ul> <p>Representa\u00e7\u00e3o mais detalhada:</p> \\[ P(e_{k+1:t} | X_k) = \\sum_{x_{k+1}} P(e_{k+1} | x_{k+1}) P(e_{k+2:t} | x_{k+1}) P(x_{k+1} | X_k) \\] <p>M\u00e9todos de suaviza\u00e7\u00e3o</p> <ul> <li>Suavizador de Kalman: Amplia o filtro de Kalman para modelos gaussianos lineares para fornecer estimativas de estado suavizadas. [11]</li> <li>Suavizador Rauch-Tung-Striebel (RTS): Uma implementa\u00e7\u00e3o espec\u00edfica do suavizador de Kalman que opera em duas passagens: filtragem para frente e suaviza\u00e7\u00e3o para tr\u00e1s. [11]</li> <li>Suaviza\u00e7\u00e3o de atraso fixo: estima estados ocultos com um atraso de tempo fixo, equilibrando precis\u00e3o e efici\u00eancia computacional. [11]</li> </ul>"},{"location":"temporal_inference/#explicacao-mais-provavel","title":"Explica\u00e7\u00e3o mais prov\u00e1vel","text":"<p>Dada uma sequ\u00eancia de observa\u00e7\u00f5es, podemos querer encontrar a sequ\u00eancia de estados com maior probabilidade de ter gerado essas observa\u00e7\u00f5es. Ou seja, queremos calcular \\( \\arg\\max_{x_{1:t}} P(x_{1:t} | e_{1:t}) \\). Os algoritmos para essa tarefa s\u00e3o \u00fateis em muitas aplica\u00e7\u00f5es, incluindo o reconhecimento de fala, em que o objetivo \u00e9 encontrar a sequ\u00eancia mais prov\u00e1vel de palavras, dada uma s\u00e9rie de sons, e a reconstru\u00e7\u00e3o de cadeias de bits transmitidas por um canal com ru\u00eddo. [1]</p> <p>Representa\u00e7\u00e3o matem\u00e1tica:</p> \\[ \\max_{X_1, ..., X_T} P(X_1, ..., X_T | O_1, ..., O_T) \\] <p>Representa\u00e7\u00e3o mais detalhada</p> \\[ m_{1:t+1} = P(e_{t+1} | X_{t+1}) \\max_{x_{t}} P(X_{t+1} | x_{t}) \\max_{x_{1:t-1}} P(x_{1:t-1}, x_{t}, e_{1:t}) \\] <p>Etapas de implementa\u00e7\u00e3o:</p> <ul> <li>Inicializa\u00e7\u00e3o: Configurar as probabilidades iniciais do estado. [11]</li> <li>Recurs\u00e3o: Para cada estado, calcule a probabilidade m\u00e1xima de cada estado que leva a ele. [11]</li> <li>Encerramento: Determine o estado final de probabilidade m\u00e1xima e rastreie o caminho mais prov\u00e1vel. [11]</li> </ul>"},{"location":"temporal_inference/#aprendizado","title":"Aprendizado","text":"<p>Os modelos de transi\u00e7\u00e3o e de sensor, se ainda n\u00e3o forem conhecidos, podem ser aprendidos com as observa\u00e7\u00f5es. Assim como nas redes bayesianas est\u00e1ticas, o aprendizado din\u00e2mico da rede Bayes pode ser feito como um subproduto da infer\u00eancia. A infer\u00eancia fornece uma estimativa de quais transi\u00e7\u00f5es realmente ocorreram e de quais estados geraram as leituras do sensor, e essas estimativas podem ser usadas para aprender os modelos. O processo de aprendizado pode operar por meio de um algoritmo de atualiza\u00e7\u00e3o iterativo chamado de maximiza\u00e7\u00e3o de expectativa ou EM, ou pode resultar da atualiza\u00e7\u00e3o bayesiana dos par\u00e2metros do modelo com base nas evid\u00eancias. [1]</p>"},{"location":"time_uncertainty/","title":"Tempo e Incerteza\u200b","text":"<p>Problemas est\u00e1ticos: S\u00e3o problemas encontrados em mundos est\u00e1ticos, nos quais cada vari\u00e1vel aleat\u00f3ria tem um \u00fanico valor fixo. Um exemplo disso seria quando vamos reparar um carro, podemos assumir que o que estava quebrado continuar\u00e1 quebrado independente do tempo que levarmos para o diagn\u00f3stico. [1]</p> <p>Problemas din\u00e2micos: Elementos din\u00e2micos s\u00e3o introduzidos ao problema, de modo que os valores das vari\u00e1veis podem mudar ao longo do tempo. Para avaliar o estado atual com base no hist\u00f3rico de evid\u00eancias e prever os resultados das a\u00e7\u00f5es de tratamento, precisamos modelar essas mudan\u00e7as. Um exemplo desses problemas seria um paciente com suspeita de diabetes pode ter sua condi\u00e7\u00e3o monitorada pelo n\u00edvel de insulina, alimentos ingeridos, etc. Mas seu estado muda com o tempo!\u200b [1]</p>"},{"location":"transition_sensors/","title":"Modelo de transi\u00e7\u00e3o e modelos de sensores","text":"<p>O modelo de transi\u00e7\u00e3o especifica a distribui\u00e7\u00e3o de probabilidade sobre as vari\u00e1veis de estado mais recentes, dados os valores anteriores, ou seja, \\( P(X_t | X_{0:t-1}) \\). Aqui, usamos a suposi\u00e7\u00e3o de Markov para que o estado atual dependa apenas de um n\u00famero fixo e finito de estados anteriores. Os processos que atendem a essa premissa s\u00e3o chamados de processos de Markov ou cadeias de Markov. [1]</p>"},{"location":"transition_sensors/#processo-de-markov-de-primeira-ordem","title":"Processo de Markov de primeira ordem","text":"<p>Aqui, o estado atual depende apenas do estado anterior e n\u00e3o de nenhum estado anterior. Em outras palavras, um estado fornece informa\u00e7\u00f5es suficientes para tornar o futuro condicionalmente independente do passado. [1]</p> \\[ P(X_t | X_{0:t-1}) = P(X_t | X_{t-1}) \\] <ul> <li>O modelo de transi\u00e7\u00e3o \u00e9 a distribui\u00e7\u00e3o condicional \\( P(X_t | X_{t-1}) \\).</li> </ul>"},{"location":"transition_sensors/#processo-de-markov-de-segunda-ordem","title":"Processo de Markov de segunda ordem","text":"<p>Aqui, o estado atual depende de dois estados anteriores.</p> \\[ P(X_t | X_{0:t-1}) = P(X_t | X_{t-2}, X_{t-1}) \\] <ul> <li>O modelo de transi\u00e7\u00e3o para um processo de Markov de segunda ordem \u00e9 a distribui\u00e7\u00e3o condicional \\( P(X_t | X_{t-2}, X_{t-1}) \\).</li> </ul> <p>Para os processos de Markov, presumimos que as mudan\u00e7as no estado do mundo s\u00e3o causadas por um processo homog\u00eaneo no tempo, ou seja, um processo de mudan\u00e7a que \u00e9 regido por leis que n\u00e3o mudam com o tempo. [1]</p>"},{"location":"transition_sensors/#pressuposto-de-markov-do-sensor","title":"Pressuposto de Markov do sensor","text":"\\[ P(E_t | X_{0:t}, E_{1:t-1}) = P(E_t | X_t) \\] <ul> <li>\\( P(E_t | X_t) \\) \u00e9 o modelo de sensor (\u00e0s vezes chamado de modelo de observa\u00e7\u00e3o).</li> <li>As vari\u00e1veis \\( E_t \\) podem depender de vari\u00e1veis anteriores, bem como das vari\u00e1veis do estado atual.</li> </ul>"},{"location":"transition_sensors/#prior-probability-distribution-at-time-0","title":"Prior probability distribution at time 0","text":"\\[ P(X_{0:t}, E_{1:t}) = P(X_0) \\prod_{i=1}^{t} P(X_i | X_{i-1}) P(E_i | X_i) \\] <ul> <li>Modelo de estado inicial \\( P(X_0) \\) </li> <li>O modelo de transi\u00e7\u00e3o \\( P(X_i | X_{i-1}) \\) </li> <li>Modelo de sensor \\( P(E_i | X_i) \\)</li> </ul> <p>Essa equa\u00e7\u00e3o define a sem\u00e2ntica da fam\u00edlia de modelos temporais representados pelos tr\u00eas termos.</p> <p>H\u00e1 duas maneiras de melhorar a precis\u00e3o da aproxima\u00e7\u00e3o:</p> <ul> <li>Aumentar a ordem do modelo do processo de Markov. [1]</li> <li>Aumentar o conjunto de vari\u00e1veis de estado. [1]</li> </ul>"},{"location":"uncertainty/","title":"Incerteza","text":""},{"location":"uncertainty/#agindo-sob-incerteza","title":"Agindo sob incerteza","text":"<p>No mundo real a incerteza \u00e9 algo que \u00e9 praticamente inevit\u00e1vel, por isso os agentes devem ser capazes de agir efetivamente apesar disso. Um dos m\u00e9todos que se usa para isso \u00e9 manter estados de cren\u00e7a, estes s\u00e3o representa\u00e7\u00f5es de todos os poss\u00edveis estados em que pode estar, a partir destes se gera planos de conting\u00eancia para cada situa\u00e7\u00e3o que possa apresentar. Embora este m\u00e9todo funcione para problemas simples, quando introduzido em ambientes mais complexos apresenta dificuldades, isto \u00e9 principalmente devido a tr\u00eas fatores. [1]</p> <ul> <li> <p>Estado de cren\u00e7as de grande porte cheio de situa\u00e7\u00f5es improv\u00e1veis, isto porque voc\u00ea deve considerar todas as situa\u00e7\u00f5es poss\u00edveis. [1]</p> </li> <li> <p>Planos de conting\u00eancia incrivelmente grandes para lidar com todas as situa\u00e7\u00f5es, mesmo aquelas com baixa probabilidade. [1]</p> </li> <li> <p>Incapacidade de comparar os m\u00e9ritos de planos que n\u00e3o garantem atingir o objetivo. [1]</p> </li> </ul> <p>Problema de qualifica\u00e7\u00e3o l\u00f3gica: N\u00e3o se pode inferir se um plano ser\u00e1 bem sucedido ou n\u00e3o, porque h\u00e1 uma quantidade incomensur\u00e1vel de condi\u00e7\u00f5es que n\u00e3o podem ser deduzidas com precis\u00e3o. [1]</p> <p>Tentar criar regras absolutas usando a l\u00f3gica como base \u00e9 imposs\u00edvel, isto devido a tr\u00eas raz\u00f5es:</p> <ul> <li> <p>Complexidade: O n\u00famero completo de antecedentes e consequentes que s\u00e3o necess\u00e1rios para criar uma regra sem exce\u00e7\u00f5es \u00e9 muito grande e as regras resultantes destes seriam muito dif\u00edceis de usar. [1]</p> </li> <li> <p>Desconhecimento te\u00f3rico: Muitos campos n\u00e3o t\u00eam a teoria completa para seu dom\u00ednio. [1]</p> </li> <li> <p>Desconhecimento pr\u00e1tico: Mesmo se todas as regras s\u00e3o conhecidas, n\u00e3o pode ser totalmente certo porque os testes necess\u00e1rios de uma determinada situa\u00e7\u00e3o n\u00e3o foram ou n\u00e3o podem ser realizados. [1]</p> </li> </ul> <p>Grau de cren\u00e7a: Os graus de cren\u00e7a representam formalmente a for\u00e7a com que um agente acredita na verdade de v\u00e1rias proposi\u00e7\u00f5es. Quanto mais alto for o grau de cren\u00e7a de um agente em uma determinada proposi\u00e7\u00e3o, maior ser\u00e1 sua confian\u00e7a na verdade dessa proposi\u00e7\u00e3o. [2] Estas probabilidades nas senten\u00e7as relevantes \u00e9 o melhor que pode ser alcan\u00e7ado com o conhecimento do agente. [1]</p>"},{"location":"utility/","title":"Utilidade","text":""},{"location":"utility/#decisoes-racionais","title":"Decis\u00f5es racionais","text":"<p>H\u00e1 uma grande quantidade de planos com diferentes probabilidades de sucesso e com m\u00faltiplas consequ\u00eancias ligadas a eles, o agente deve ter uma forma de escolher um destes tentando conseguir um equil\u00edbrio entre a probabilidade de sucesso e consequ\u00eancias que podem ser desej\u00e1veis ou indesej\u00e1veis. [1]</p> <p>Prefer\u00eancia: Refere-se \u00e0 tend\u00eancia dos agentes de escolher certos planos sobre outros. A prioridade geralmente depende das condi\u00e7\u00f5es que cercam as solu\u00e7\u00f5es desses planos. [1]</p>"},{"location":"utility/#teoria-da-utilidade","title":"Teoria da utilidade","text":"<p>Esta teoria sugere que cada poss\u00edvel resultado de uma decis\u00e3o \u00e9 atribu\u00eddo um valor que representa qu\u00e3o satisfeito se esta com o resultado. O objetivo \u00e9 obter o maior valor esperado, que \u00e9 a m\u00e9dia dos valores de todos os resultados poss\u00edveis, levando em conta a probabilidade de cada um deles acontecer. [4] Na intelig\u00eancia artificial, pode-se dizer que cada estado (ou sequ\u00eancia de estados) tem um grau de utilidade para um agente e que o agente preferir\u00e1 estados com maior utilidade. [1] Essa utilidade \u00e9 relativa ao agente, ou seja, um estado que pode ser considerado de alta utilidade para um agente pode ser considerado de baixa utilidade para outro que tem um objetivo e condi\u00e7\u00f5es desejadas diferentes. [1]</p>"}]}